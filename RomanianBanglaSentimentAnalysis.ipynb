{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTJ7ln5jZ1kGwZYZaabu09",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashibullah/Romanian-Bangla-Sentiment-Analysis-NLP/blob/main/RomanianBanglaSentimentAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "-h08gX8Df4Cg"
      },
      "outputs": [],
      "source": [
        "!pip install datasets --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "tz3SF_EKWkF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')  # For tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkpH-xM9WnC-",
        "outputId": "31256daa-cfd5-4f1e-a30f-576608ceb090"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from textblob import TextBlob\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "import json"
      ],
      "metadata": {
        "id": "is9rz2vygTFi"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCLyXoH0yxAB",
        "outputId": "da005b49-097f-4b82-c4e8-54140ecf6745"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_dataset(\"aplycaebous/BnSentMix\" , split = \"train\")"
      ],
      "metadata": {
        "id": "x1eXqhC1iL0C",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zRBhvPHnvEUQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    return text"
      ],
      "metadata": {
        "id": "hILT6_kjsRpI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_text(text):\n",
        "    return str(TextBlob(text).correct())"
      ],
      "metadata": {
        "id": "hi1EvFEZvORq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDl8MTN4ifFO",
        "outputId": "7ed3f345-17f2-4121-9a24-b2678a4225eb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Sentence': 'Vloi bt cash out korte 15 takar jaigai 18.50 paisa nei', 'Label': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrame\n",
        "df = pd.DataFrame(df)\n",
        "# Convert 'Sentence' column to lowercase\n",
        "df['Sentence'] = df['Sentence'].str.lower()\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "aAajerISpyT4",
        "outputId": "3251fbcb-f984-41c0-afe4-a4275bf6f83c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Sentence  Label  \\\n",
            "0      youtube ar volg gula boring hoia jaitase din d...      3   \n",
            "1      your video making camera work is really good i...      3   \n",
            "2      you made me nostalgic college life a ei dokan ...      3   \n",
            "3      workshop ta engaging but resources ta insuffic...      3   \n",
            "4                      win hoy nay but anek valo khelecu      3   \n",
            "...                                                  ...    ...   \n",
            "20010  1 march use kortasi pocof5 kono problem nai ga...      0   \n",
            "20011                       1 day beshi stay kora jae na      0   \n",
            "20012            1 boro na 2 boro tushar vai er mon boro      0   \n",
            "20013               1 boro na 2 boro sam vai er mon boro      0   \n",
            "20014  058 pcbbd er depression boys mone hoillo minar...      0   \n",
            "\n",
            "                                                  Tokens  \n",
            "0      [youtube, ar, volg, gula, boring, hoia, jaitas...  \n",
            "1      [your, video, making, camera, work, is, really...  \n",
            "2      [you, made, me, nostalgic, college, life, a, e...  \n",
            "3      [workshop, ta, engaging, but, resources, ta, i...  \n",
            "4              [win, hoy, nay, but, anek, valo, khelecu]  \n",
            "...                                                  ...  \n",
            "20010  [1, march, use, kortasi, pocof5, kono, problem...  \n",
            "20011               [1, day, beshi, stay, kora, jae, na]  \n",
            "20012  [1, boro, na, 2, boro, tushar, vai, er, mon, b...  \n",
            "20013    [1, boro, na, 2, boro, sam, vai, er, mon, boro]  \n",
            "20014  [058, pcbbd, er, depression, boys, mone, hoill...  \n",
            "\n",
            "[20015 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# remove urls\n",
        "df['Sentence'] = df['Sentence'].apply(clean_text)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZQZ_1uMpsNdc",
        "outputId": "9c4f058e-5a47-4a2e-aa99-3e353ca930ec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Sentence  Label  \\\n",
            "0      youtube ar volg gula boring hoia jaitase din d...      3   \n",
            "1      your video making camera work is really good i...      3   \n",
            "2      you made me nostalgic college life a ei dokan ...      3   \n",
            "3      workshop ta engaging but resources ta insuffic...      3   \n",
            "4                      win hoy nay but anek valo khelecu      3   \n",
            "...                                                  ...    ...   \n",
            "20010  1 march use kortasi pocof5 kono problem nai ga...      0   \n",
            "20011                       1 day beshi stay kora jae na      0   \n",
            "20012            1 boro na 2 boro tushar vai er mon boro      0   \n",
            "20013               1 boro na 2 boro sam vai er mon boro      0   \n",
            "20014  058 pcbbd er depression boys mone hoillo minar...      0   \n",
            "\n",
            "                                                  Tokens  \n",
            "0      [youtube, ar, volg, gula, boring, hoia, jaitas...  \n",
            "1      [your, video, making, camera, work, is, really...  \n",
            "2      [you, made, me, nostalgic, college, life, a, e...  \n",
            "3      [workshop, ta, engaging, but, resources, ta, i...  \n",
            "4              [win, hoy, nay, but, anek, valo, khelecu]  \n",
            "...                                                  ...  \n",
            "20010  [1, march, use, kortasi, pocof5, kono, problem...  \n",
            "20011               [1, day, beshi, stay, kora, jae, na]  \n",
            "20012  [1, boro, na, 2, boro, tushar, vai, er, mon, b...  \n",
            "20013    [1, boro, na, 2, boro, sam, vai, er, mon, boro]  \n",
            "20014  [058, pcbbd, er, depression, boys, mone, hoill...  \n",
            "\n",
            "[20015 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df['Sentence'].apply(correct_text)\n",
        "# avoiding this"
      ],
      "metadata": {
        "id": "Kjw1OlD-ua1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_path = '/content/drive/MyDrive/Colab Notebooks/RomanianBanglaUtilities/normalization_dict.json'\n",
        "with open(dict_path, 'r', encoding='utf-8') as f:\n",
        "    normalization_dict = json.load(f)\n",
        "\n",
        "print(f\"Loaded normalization dictionary with {len(normalization_dict)} entries\")\n",
        "\n",
        "\n",
        "# Function to normalize text using your dictionary\n",
        "def normalize_text(text, norm_dict):\n",
        "    tokens = text.split()\n",
        "    reverse_map = {}\n",
        "    for std_word, variants in norm_dict.items():\n",
        "        reverse_map[std_word] = std_word\n",
        "        for var in variants:\n",
        "            reverse_map[var] = std_word\n",
        "    normalized_tokens = [reverse_map.get(token.lower(), token.lower()) for token in tokens]\n",
        "    return ' '.join(normalized_tokens)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9BQYDk80y-vJ",
        "outputId": "597e8aac-3a78-465b-b628-75d8c3b8fe48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded normalization dictionary with 55 entries\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sentence'] = df['Sentence'].apply(lambda x: normalize_text(x, normalization_dict))"
      ],
      "metadata": {
        "id": "HBFH7rNY0Cay"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Tokens'] = df['Sentence'].apply(word_tokenize)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7yZUKax0VgE",
        "outputId": "16b4d0d6-6e61-48f9-bf40-8ff14cbe087d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Sentence  Label  \\\n",
            "0  youtube ar volg gula boring hoia jaitase din d...      3   \n",
            "1  your video making camera work is really good i...      3   \n",
            "2  you made me nostalgic college life a ei dokan ...      3   \n",
            "3  workshop ta engaging but resources ta insuffic...      3   \n",
            "4                 win hoy nay but anek bhalo khelecu      3   \n",
            "\n",
            "                                              Tokens  \n",
            "0  [youtube, ar, volg, gula, boring, hoia, jaitas...  \n",
            "1  [your, video, making, camera, work, is, really...  \n",
            "2  [you, made, me, nostalgic, college, life, a, e...  \n",
            "3  [workshop, ta, engaging, but, resources, ta, i...  \n",
            "4         [win, hoy, nay, but, anek, bhalo, khelecu]  \n"
          ]
        }
      ]
    }
  ]
}